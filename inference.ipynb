{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: ./temp/model_199.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "from trainer import Trainer\n",
    "import wandb\n",
    "\n",
    "\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# torch.backends.cudnn.allow_tf32 = True\n",
    "# torch.set_float32_matmul_precision('high')\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.set_float32_matmul_precision('highest')\n",
    "\n",
    "\n",
    "\n",
    "config = yaml.safe_load(\n",
    "r\"\"\"\n",
    "data:\n",
    "    dataset: old_noisy_cifar10\n",
    "    noise_type: symmetric\n",
    "    noise_rate: 0.5\n",
    "    random_seed: 42\n",
    "\n",
    "model:\n",
    "    architecture: resnet34\n",
    "    num_classes: 10\n",
    "\n",
    "trainer:\n",
    "    num_workers: 4\n",
    "    batch_size: 128\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "## Load model\n",
    "import models\n",
    "\n",
    "model = models.get_model(**config[\"model\"])\n",
    "\n",
    "wandb_run_id = \"2cvre1ep\"\n",
    "\n",
    "def load_checkpoint(name=\"model_199.pth\"):\n",
    "    checkpoint = wandb.restore(name, run_path=f\"hyounguk-shon/noisy-label/{wandb_run_id}\", replace=False, root='./temp')\n",
    "    model.load_state_dict(torch.load(checkpoint.name, map_location=\"cpu\"))\n",
    "    print(f\"Loaded checkpoint: {checkpoint.name}\")\n",
    "\n",
    "load_checkpoint(\"model_199.pth\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    config=config['trainer'],\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "True noise rate: 0.4501\n",
      "Files already downloaded and verified\n",
      "Dataset OldNoisyCIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: /dev/shm/data/\n",
      "    Split: Train\n"
     ]
    }
   ],
   "source": [
    "## Load dataset\n",
    "import datasets\n",
    "\n",
    "train_dataset, test_dataset = datasets.get_dataset(**config[\"data\"])\n",
    "\n",
    "dataset = train_dataset\n",
    "dataset.transform = datasets.get_transform('none', dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[-0.5065, -1.4981, -4.9593,  ..., -1.0978,  1.9800, -2.1671],\n",
       "         [-3.7119, -3.9473,  1.2110,  ...,  0.0594, -9.7636, 17.0981],\n",
       "         [-3.4245, -2.2070, -4.2968,  ..., -4.9050,  2.7233, 13.2970],\n",
       "         ...,\n",
       "         [15.5436, -5.0751, -3.2363,  ..., -0.0580, -0.1786,  0.4635],\n",
       "         [ 3.4131, 16.4452, -1.4655,  ..., -1.4378, -3.9767, -6.4341],\n",
       "         [-2.5247, 13.6361,  1.0942,  ...,  2.2141,  5.3886,  0.7559]]),\n",
       " 'target': tensor([4, 6, 9,  ..., 5, 8, 1]),\n",
       " 'target_gt': tensor([6, 9, 9,  ..., 9, 1, 1])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run inference\n",
    "results = trainer.inference(dataset)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5511)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results['logits'].max(-1).indices == results['target_gt']).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:28<00:00,  7.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[[  3.1371,  -7.2377,  -3.8441,  ...,  -5.2848,   0.5542,   2.5441],\n",
       "          [  1.0813,  -2.6185,  -0.9506,  ...,  -3.1691,  -2.2103,  -2.6586],\n",
       "          [  4.0872,  -5.1103,   3.2242,  ...,   1.0411,  -0.2065,  -3.1807],\n",
       "          ...,\n",
       "          [ -0.5065,  -1.4981,  -4.9593,  ...,  -1.0978,   1.9800,  -2.1671],\n",
       "          [ -2.5059,  -1.8346,  -6.5934,  ...,   0.4153,   2.7932,  -0.9255],\n",
       "          [  2.7689,   1.0047,  -6.2310,  ...,   5.8537,   0.7352,   3.2017]],\n",
       " \n",
       "         [[ -3.9351,  -4.2672,   1.2846,  ...,  -2.4506,  -4.8029,  13.6650],\n",
       "          [ -3.7119,  -3.9473,   1.2110,  ...,   0.0594,  -9.7636,  17.0981],\n",
       "          [ -3.5406,  -3.8940,   1.7314,  ...,  -0.4538,  -9.5749,  16.9001],\n",
       "          ...,\n",
       "          [ -3.7119,  -3.9473,   1.2110,  ...,   0.0594,  -9.7636,  17.0981],\n",
       "          [  4.7519,   4.2068,  -6.3249,  ...,   2.9229, -10.9448,  16.8736],\n",
       "          [  2.0416,   2.5977,   0.1642,  ...,  -3.4261,  -5.0222,   4.4338]],\n",
       " \n",
       "         [[ -3.4245,  -2.2070,  -4.2968,  ...,  -4.9050,   2.7233,  13.2970],\n",
       "          [ -1.4770,   0.1965,  -4.1647,  ...,  -6.4311,   1.7787,  12.6914],\n",
       "          [ -1.0233,   2.6553,  -0.3166,  ...,  -3.4775,   0.1307,   0.6876],\n",
       "          ...,\n",
       "          [  2.9295,  -1.5441,   1.5047,  ...,  -1.0514,  -0.6722,   2.4376],\n",
       "          [ -3.4245,  -2.2070,  -4.2968,  ...,  -4.9050,   2.7233,  13.2970],\n",
       "          [  6.4656,  -0.6604,   0.3315,  ...,  -4.1412,   1.8655,   0.0850]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 13.7310,  -4.9864,  -2.7801,  ...,  -2.5792,  -0.8215,   0.3462],\n",
       "          [ 14.5123,  -4.0110,  -2.9768,  ...,   1.1049,  -1.4213,   0.6078],\n",
       "          [ 10.7944,   0.3482,  -1.3140,  ...,  -0.9671,   1.7693,  -0.8400],\n",
       "          ...,\n",
       "          [ -1.0047,  -4.8078,  -2.8375,  ...,  -0.8392,   0.6556,   0.5773],\n",
       "          [ 15.3650,  -7.1266,  -1.5500,  ...,   0.9338,   0.3578,   1.7481],\n",
       "          [  8.1071,  -2.7914,  -1.6607,  ...,  -2.3637,   0.9428,   2.4393]],\n",
       " \n",
       "         [[  3.4131,  16.4452,  -1.4655,  ...,  -1.4378,  -3.9767,  -6.4341],\n",
       "          [  3.4131,  16.4452,  -1.4655,  ...,  -1.4378,  -3.9767,  -6.4341],\n",
       "          [ -0.3744,   4.5822,  -2.1158,  ...,   3.9003,   3.0255,   0.4883],\n",
       "          ...,\n",
       "          [ -1.3989,   4.8352,   2.0097,  ...,   3.9624,  -0.6592,   2.8544],\n",
       "          [ -0.8195,  13.1900,   4.1257,  ...,  -4.7836,  -4.5497,  -2.7987],\n",
       "          [ 10.3691,   4.8988,  -1.2369,  ...,   0.1429,  -0.8317,  -5.8525]],\n",
       " \n",
       "         [[ -7.6832,   6.1664,  -0.4931,  ...,   0.1839,   0.5456,  -1.1994],\n",
       "          [ -2.5247,  13.6361,   1.0942,  ...,   2.2141,   5.3886,   0.7559],\n",
       "          [ -5.7669,  10.2218,   5.1446,  ...,   2.8338,   8.5223,  -1.4392],\n",
       "          ...,\n",
       "          [  1.8208,  -1.2583,  -4.8872,  ...,  -2.7765,   6.1682,   7.2846],\n",
       "          [ -2.4648,  13.7668,   0.7702,  ...,   1.6792,   4.9094,   1.1801],\n",
       "          [ -2.5247,  13.6361,   1.0942,  ...,   2.2141,   5.3886,   0.7559]]]),\n",
       " 'target': tensor([[4, 4, 4,  ..., 4, 4, 4],\n",
       "         [6, 6, 6,  ..., 6, 6, 6],\n",
       "         [9, 9, 9,  ..., 9, 9, 9],\n",
       "         ...,\n",
       "         [5, 5, 5,  ..., 5, 5, 5],\n",
       "         [8, 8, 8,  ..., 8, 8, 8],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'target_gt': tensor([[6, 6, 6,  ..., 6, 6, 6],\n",
       "         [9, 9, 9,  ..., 9, 9, 9],\n",
       "         [9, 9, 9,  ..., 9, 9, 9],\n",
       "         ...,\n",
       "         [9, 9, 9,  ..., 9, 9, 9],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run multiple inferences to aggregate results over random augmentations\n",
    "\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "\n",
    "dataset.transform = datasets.get_transform('autoaugment', dataset)\n",
    "\n",
    "n_repeat = 20\n",
    "\n",
    "many_results = defaultdict(list)\n",
    "for _ in tqdm.trange(n_repeat):\n",
    "    results = trainer.inference(dataset)\n",
    "    for k, v in results.items():\n",
    "        many_results[k].append(v)\n",
    "many_results = {k: torch.stack(v, dim=1) for k, v in many_results.items()} # shape is (n_samples, n_repeat, ...)\n",
    "many_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5801)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(many_results['logits'].mean(1).max(-1).indices == many_results['target_gt'][:,0]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results\n",
    "# torch.save(results, \"results.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
